---
title: "When Will AGI/Singularity Happen? 8,590 Predictions Analyzed"
source: https://research.aimultiple.com/artificial-general-intelligence-singularity-timing
date: 2025-08-07
description: "Explore key predictions on artificial general intelligence from experts and insights from five major AI surveys on AGI timelines."
word_count: 8538
---

AI
Agentic AI
Cybersecurity
Data
Enterprise Software
Contact Us
Back
No results found.
[](https://research.aimultiple.com/<https:/aimultiple.com/>)AIAI Foundations
# When Will AGI/Singularity Happen? 8,590 Predictions Analyzed

Cem Dilmegani
with 
Sƒ±la Ermut
updated on Dec 5, 2025
See our ethical norms
Expand Image
!Graph showing the interest of the keyword 
We analyzed 8,590 scientists‚Äô, leading entrepreneurs‚Äô, and the community‚Äôs predictions for quick answers on Artificial General Intelligence (AGI) / singularity timeline:
  * **Will AGI/singularity ever happen?** According to most AI experts, AGI is inevitable.
  * **When will the singularity/AGI happen?** Recent surveys of AI researchers predict AGI around 2040. However, a few years before the rapid advances in large language models (LLMs), scientists predicted it for around 2060. Entrepreneurs are even more bullish, predicting it around ~2030.
  * **What is our current status?** Although narrow AI surpasses humans in specific tasks, a generally intelligent machine doesn‚Äôt exist. Some researchers believe that large language models demonstrate emerging generalist capabilities.1  According to our AGI benchmark, machines are far from generating economic value autonomously.
  * **How can we reach AGI?** Either by putting more compute and data behind current architectures like transformers, or by inventing new approaches. There is no scientific consensus yet on the method for achieving AGI or for validating it.

Explore key predictions on AGI from experts like Sam Altman and Demis Hassabis, insights from major AI surveys on AGI timelines, and arguments for and against the feasibility of AGI:
## Artificial General Intelligence timeline
This timeline outlines the anticipated year of the singularity, based on insights gathered from 15 surveys, including responses from 8,590 AI researchers, scientists, and participants in prediction markets:
As you can see above, survey respondents are increasingly expecting the singularity to occur earlier than previously expected.
Here is how we created this graph:
  * To plot the expected year of AGI development on the graph, we used the average of the predictions for each year.
  * For individual predictions, we included forecasts from 12 different AI experts.
  * For scientific predictions, we gathered estimates from 8 peer-reviewed papers authored by AI researchers.
  * For the Metaculus community predictions, we used the average forecast dates from 3,290 predictions submitted in 2020 and 2022 on the publicly accessible Metaculus platform.

Below you can see the studies and predictions that make up this timeline, or skip to understanding the singularity.
### Results of major surveys of AI researchers
We examined the results of 10 surveys involving over 5,288 AI researchers and experts, where they estimated when AGI/singularity might occur.
While predictions vary, most surveys indicate a 50% probability of achieving AGI **between 2040 and 2061,** with some estimating that superintelligence could follow within a few decades.
#### AAAI 2025 Presidential Panel on the Future of AI Research
475 respondents, mainly from academia (67%) and North America (53%), were asked about progress in AI. Though the survey didn‚Äôt ask for a timeline for AGI, 76% of respondents shared that scaling up current AI approaches would be unlikely to lead to AGI.2 
#### 2023 Expert Survey on Progress in AI
In October, AI Impacts surveyed 2,778 AI researchers on when AGI might be achieved. This survey included nearly identical questions to the 2022 survey. Based on the results, the high-level machine intelligence is estimated to occur by **2040**.3 
#### 2022 Expert Survey on Progress in AI
The survey was conducted with 738 experts who published at the 2021 NIPS and ICML conferences. AI experts estimate that there‚Äôs a **50%** chance that high-level machine intelligence will occur by **2059.** 4 
Experts also predicted that hardware cost, algorithmic progress, and work on training sets would be the biggest factors in AI progress.
#### Forecasting AI progress survey in 2019
Baobao Zhang surveyed 296 AI experts, asking them to predict when machines would surpass the median human worker in performing over 90% of economically relevant tasks. Half of the respondents estimated this would happen before **2060**.5 
#### AI experts‚Äô survey on AGI timing in 2019
The predictions of 32 AI experts on AGI timing6 are:
  * **45%** of respondents predict a date before **2060.**
  * **34%** of all participants predicted a date after **2060.**
  * **21%** of participants predicted that the singularity would never occur.

#### Survey on AI‚Äôs potential impact on labor displacement in 2018
Ross Gruetzemacher surveyed 165 AI experts to assess the potential impact of AI on labor displacement. The experts were asked to estimate when AI systems would be capable of performing 99% of tasks for which humans are currently paid, at a level equal to or exceeding that of an average human. 
Half of the respondents predicted this milestone would be reached before **2068** , while 75% anticipated it would occur within the next 100 years.7 
#### AI experts in the 2015 NIPS and ICML conferences survey in 2017
In May 2017, 352 AI experts who published at the 2015 NIPS and ICML conferences were surveyed.8 
Based on survey results, experts estimate that there‚Äôs a **50% chance** that AGI will occur **by 2060.** That said, there‚Äôs a significant difference of opinion based on geography: 
  * Asian respondents expect AGI in 30 years,
  * North Americans expect it in 74 years. 

Some significant job functions expected to be automated by 2030 include call center reps, truck driving, and retail sales.
#### Future Progress in Artificial Intelligence survey in 2012/2013
Vincent C. Muller, the president of the European Association for Cognitive Systems, and Nick Bostrom from the University of Oxford, who published over 200 articles on superintelligence and artificial general intelligence (AGI), conducted a survey of AI researchers. 550 participants answered the question: When is AGI likely to happen?9 
According to the results:
  * The surveyed AI experts estimate that AGI will probably (over 50% chance) emerge between **2040 and 2050** and is highly likely (90% chance) to appear by **2075.**
  * Once AGI is reached, most experts believe it will progress to super-intelligence relatively quickly, with a timeframe ranging from as little as 2 years (unlikely, 10% probability) to about 30 years (high probability, 75%).

#### 2009 survey with AI experts participating in the AGI-09 conference
Based on the results of the survey with 21 AI experts participating in the AGI-09 conference, it is believed that AGI will occur around **2050** , and plausibly sooner.10 You can see below their estimates regarding specific AI achievements: passing the Turing test, passing third grade, accomplishing Nobel-worthy scientific breakthroughs, and achieving superhuman intelligence.
Expand Image
!Survey results on "When will singularity/AGI happen?" with 21 AI experts.
Figure 1: Results from the survey distributed to attendees of the Artificial General Intelligence 2009 (AGI-09) conference.
### Other comments and developments about AGI
#### OpenAI expands its robotics ambitions
OpenAI is increasing its focus on robotics as part of its goal to advance artificial general intelligence. The company is hiring specialists in humanoid robot systems and forming a team to design algorithms that help robots learn and act independently in the physical world.
This marks a shift from OpenAI‚Äôs earlier focus on language and image models. The company now aims to connect advanced reasoning with physical interaction, suggesting it views robotics as an essential step toward testing and achieving AGI.
**Context and implications**
After winding down its first robotics team around 2020, OpenAI is returning to active development in the field. Recent hiring and potential partnerships point to a renewed effort to build robots capable of real-world learning and manipulation.
By combining large-scale AI models with sensory data, OpenAI aims to create systems that can reason and operate outside digital environments. The recruitment of humanoid robotics experts also indicates long-term goals that go beyond automation and toward robots that can work safely alongside people.11 
#### Microsoft‚Äôs report on early experiments with GPT-4
Microsoft Research studied an early version of OpenAI‚Äôs GPT-4 in 2023. The report claimed that it showed greater general intelligence than previous AI models, **performing at a human level** in areas like math, coding, and law. This sparked debate on whether **GPT-4 was a preliminary form of artificial general intelligence**. 12 
#### The road to artificial general intelligence report by MIT
‚ÄúThe road to artificial general intelligence‚Äù report in August 2025 anticipates that early AGI-like systems could begin emerging **between 2026 and 2028** , showing human-level reasoning within specific domains, multimodal capabilities across text, audio, and physical interfaces, and limited goal-directed autonomy. 
The report combines aggregated forecasts and suggests a 50% probability that several generalized milestones, such as knowledge transfer and broad reasoning, will be achieved by **2028**. 
Longer-range projections estimate that machines may surpass human performance in all economically valuable tasks by around **2047** , contingent on advances in compute efficiency, algorithmic breakthroughs, and autonomous learning.13 
#### AI Frontiers on AGI probabilities
Adam Khoja and Laura Hiscott from AI Frontiers, a platform for AI debates and dialogues, estimate a **50% probability of reaching AGI by 2028** and an **80% probability by 2030** , using their quantitative AGI definition.14 
Khoja and Hiscott evaluate progress toward artificial general intelligence using a definition developed by Khoja, Dan Hendrycks, and their co-authors.15 Their framework measures ten cognitive abilities and assigns GPT-4 a score of 27% and GPT-5 a score of 57%. This indicates that current models are roughly halfway to the defined AGI threshold.
Khoja and Hiscott argue that traditional discussions about AGI timelines lack precision because they rely on inconsistent definitions. Their standardized framework is intended to create clarity by identifying specific strengths and weaknesses in current models. They note that reading, writing, mathematics, and general knowledge already meet or exceed human baselines and are no longer limiting factors.
The authors highlight remaining gaps in visual reasoning, intuitive physics, auditory processing, perception-dependent speed, and visual and auditory working memory. They report rapid improvement on benchmarks such as SPACE and MindCube and suggest these gaps can likely be addressed through continued incremental research. They also observe that hallucinations remain a concern but are tractable given performance differences across leading models.
According to Khoja, Hiscott, and Hendrycks, the most significant remaining obstacle is continual learning and long-term memory storage. Current systems cannot retain information across sessions, and resolving this limitation will require at least one meaningful breakthrough. However, the authors emphasize that major AI labs are now prioritizing this area.
### Community insights
We also evaluated Metaculus community predictions on AGI, which involved the predictions of more than 3,290 participants:
  * As of December 2025, 1,700 participants answered the question ‚ÄúWhen will the first weakly general AI system be devised, tested, and publicly announced?‚Äù and the prediction is ****31 Oct 2027****.16 
  * In 2022, 172 participants answered the question ‚ÄúWhen will an AI first pass a long, informed, adversarial Turing test?‚Äù and their prediction was **2029**.17 
  * In 2022, 81 participants answered the question ‚ÄúWhen will top forecasters expect the first Artificial General Intelligence to be developed and demonstrated?‚Äù and their prediction was **2035**.18 
  * In 2020, 1,474 participants answered the question ‚ÄúWhen will the first general AI system be devised, tested, and publicly announced?‚Äù and their prediction was **2030**.19 

### Insights from AI entrepreneurs & individual researchers
AI entrepreneurs are also making estimates on when we will reach singularity, and they are more optimistic than researchers. This is expected as they benefit from increased interest in AI.
Here are the predictions of 13 of the most prominent AI entrepreneurs and researchers:
  * Combining AI‚Äôs progress in reasoning, programming, and mathematics, Eric Schmidt, former CEO of Google, believes we are heading toward Artificial General Intelligence within **3‚Äì5 years** (as stated in April 2025).20 
  * Elon Musk expects development of an artificial intelligence smarter than the smartest of humans by **2026**.21 
  * Dario Amodei, CEO of Anthropic, expects the singularity by **2026**.22 
  * In February 2025, entrepreneur and investor Masayoshi Son predicted it in 2-3 years (i.e., **2027** or **2028**)23 
  * In March 2024, Nvidia CEO Jensen Huang predicted that within five years, AI would match or surpass human performance on any test:**2029.** 24 
  * Louis Rosenberg, computer scientist, entrepreneur, and writer, by **2030**. 
  * Ray Kurzweil, computer scientist, entrepreneur, and writer of 5 national best sellers, including The Singularity Is Near: Previously 2045,25 , in 2024, **2032**.26 
  * In 2023, Hinton believed that it could take 5-20 years.27 
  * Demis Hassabis, founder of DeepMind, by **2035**.28 
  * Sam Altman, CEO of OpenAI, by **2035**. He mentioned ‚Äúa few thousand days‚Äù in 2024 in his blog ‚ÄúThe Intelligence Age‚Äù.
  * Ajeya Cotra, an AI researcher, analyzed the growth of training computation and estimated a 50% chance that AI with human-like capabilities will emerge by **2040**.29 
  * Patrick Winston, MIT professor and director of the MIT Artificial Intelligence Laboratory from 1972 to 1997, mentioned **2040,** emphasizing that although it is a date that would occur, it is tough to estimate.
  * J√ºrgen Schmidhuber, co-founder at AI company NNAISENSE and director of the Swiss AI lab IDSIA, by **2050.** 30 

## Learning from past over-optimism in AI predictions
Keep in mind that AI researchers were over-optimistic before. Examples include:
  * Geoff Hinton claimed in 2016 that we wouldn‚Äôt need radiologists by 2021 or 2026. So far, radiology hasn‚Äôt been fully automated, and hospitals need thousands of them.31 
  * AI pioneer Herbert A. Simon in 1965: ‚Äúmachines will be capable, within twenty years, of doing any work a man can do.‚Äù32 
  * Japan‚Äôs Fifth Generation Computer in 1980 had a ten-year timeline with goals like ‚Äúcarrying on casual conversations‚Äù.33 

This historical experience contributed to most current scientists shying away from predicting AGI in bold time frames like 10-20 years, but this has changed with the rise of generative AI.
## Understand what singularity is
Artificial intelligence scares and intrigues us. Almost every week, there‚Äôs a new AI scare on the news, like developers afraid of what they‚Äôve created or shutting down bots because they got too intelligent.34 
Most of these myths result from research misinterpreted by those outside the AI and GenAI fields. Some stakeholders claim to fear AI because they may profit from more regulation, or it may bring them more attention.
The greatest fear about AI is singularity (also called Artificial General Intelligence or AGI), which is an event that is expected to bring a rapid increase in machine intelligence. This is expected when a system combines human-level thinking with superhuman speed and rapidly accessible, near-perfect memory. According to some experts, singularity also implies machine consciousness.
Such a machine could self-improve and surpass human capabilities. Even before artificial intelligence was a computer science research topic, science fiction writers like Asimov were concerned about this. They were devising mechanisms (i.e., Asimov‚Äôs Laws of Robotics) to ensure the benevolence of intelligent machines, which is more commonly called alignment research today.
## Why experts believe AGI is inevitable: Key arguments & evidence
Reaching AGI may seem like a wild prediction, but it seems like quite a reasonable goal when you consider these facts:
  * Human intelligence is fixed unless we somehow merge our cognitive capabilities with machines. Elon Musk‚Äôs neural lace startup aims to do this, but research on brain-computer interfaces is in the early stages.35 
  * Machine intelligence depends on algorithms, processing power, and memory. Processing power and memory have been growing at an exponential rate. As for algorithms, until now, we have been good at supplying machines with the necessary algorithms to use their processing power and memory effectively.

Considering that our intelligence is fixed and machine intelligence is growing, it is only a matter of time before machines surpass us unless there‚Äôs some hard limit to their intelligence. We haven‚Äôt encountered such a limit yet.
### Recent achievements
On August 7, 2025, OpenAI announced GPT-5, the most developed GPT model to date. 
GPT-5 represents a strong step forward in narrow AI, with OpenAI promoting it as ‚ÄúPhD-level‚Äù in reasoning, coding, and writing, while also reducing hallucinations and exhibiting a more human-like demeanor. 
Sam Altman, OpenAI‚Äôs CEO, described it as the first model that feels like talking to an expert on any topic. Yet, critics urge caution. Prof. Carissa V√©liz of Oxford‚Äôs Institute for Ethics in AI argues that systems like GPT-5 only mimic human reasoning rather than truly emulate it, warning that the hype may outpace reality. 
Similarly, Gaia Marcus of the Ada Lovelace Institute stresses that as models become more powerful, regulation lags dangerously behind.36 
This tension underscores GPT-5‚Äôs significance: it is a powerful evolutionary step that enhances reliability and usefulness, but it also shows the limits of current AI approaches and how far the field still is from achieving genuine AGI.37 
Another example is DeepMind‚Äôs Gemini in Deep Think mode, which achieved gold-medal performance at the 2025 International Mathematical Olympiad, marking a significant step in AI‚Äôs ability to reason through complex problems.
Operating entirely in natural language, Gemini solved five out of six problems within the official 4.5-hour contest window, while producing clear, human-readable proofs without relying on formal symbolic tools. 
Its capabilities stem from several innovations: Deep Think mode enables parallel exploration of solution paths, training incorporates expert-level mathematical proofs, and reinforcement learning refines its strategic approach. 
This progress demonstrates that advanced AI can now engage in sophisticated, interpretable reasoning at a level once reserved for top human problem-solvers.38 
### Exponential growth
The following is a helpful analogy for understanding exponential growth. While machines may not seem highly intelligent right now, they can become quite smart in the near future.
Expand Image
!Illustration of exponential growth
Source: Mother Jones
### Recent growth in AI computing capabilities
Expand Image
!The figure shows a summary of the compute growth patterns observed across various categories.
Figure 2: The figure shows a summary of the compute growth patterns observed across various categories: overall notable models (top left), frontier models (top right), leading language models (bottom left), and top models from leading companies (bottom right).
Computational resources for training AI models have significantly increased, with about two-thirds of language model performance attributed to model scale improvements. 
According to a 2024 article,39 the growth of compute usage in training AI models has consistently increased by around 4-5x per year, reflecting trends in notable models, frontier models, and top companies like OpenAI, Google DeepMind, and Meta AI (See Figure 2).
However, the growth rate has slowed somewhat since 2018, especially for frontier models, but language models have experienced faster growth up to 9x/year until mid-2020, after which the pace slowed to 4-5x/year.
The overall trend for AI compute growth remains strong, and projections suggest that the growth rate of 4-5x/year will continue unless new challenges or breakthroughs occur. This growth is also seen in the scaling strategies of leading AI companies, though slight variations exist between them. 
Despite a slowdown in frontier model growth, the larger models released today, such as GPT-4 and Gemini Ultra, align closely with the predicted growth trajectory.
### If classic computing slows, quantum computing may fill the gap 
Classic computing has taken us quite far. AI algorithms on classical computers can exceed human performance in specific tasks like playing chess or Go. For example, AlphaGo Zero beat AlphaGo by 100-0. AlphaGo had beaten the best players on earth.40 However, we are approaching the limits of how fast classical computers can be.
Moore‚Äôs law, which is based on the observation that the number of transistors in a dense integrated circuit doubles about every two years, implies that the cost of computing halves approximately every 2 years.
On the other hand, most experts believe that Moore‚Äôs law is coming to an end during this decade.41  However, there are efforts to keep improving the efficiency of computing.
For example, DeepSeek surprised global markets with its R1 model by delivering a reasoning model at a fraction of the cost of its competitors, like OpenAI.
Quantum Computing, which is still an emerging technology, can contribute to reducing computing costs after Moore‚Äôs law comes to an end. Quantum Computing is based on the evaluation of different states at the same time, whereas classical computers can calculate one state at a time.
The unique nature of quantum computing can be used to efficiently train neural networks, currently the most popular AI architecture in commercial applications. AI algorithms running on stable quantum computers have a chance to unlock the singularity.
## Why do some experts believe that we will not reach AGI?
There are 3 major arguments against the importance or existence of AGI. We examined them along with their common rebuttals:
### 1- Intelligence is multi-dimensional
Therefore, AGI will be different, not necessarily superior to human intelligence.
This is true, and human intelligence is also different from animal intelligence. Some animals are capable of mental feats, like squirrels remembering where they hid hundreds of nuts for months.
Yann LeCun, one of the pioneers of deep learning, believes that we should retire the word AGI and focus on achieving ‚Äúadvanced machine intelligence‚Äù.42 He argues the human mind is specialized and intelligence is a collection of skills and the ability to learn new skills. Each human can only accomplish a subset of human intelligence tasks.43 
It is also hard to understand the specialization level of the human mind, as humans, since we don‚Äôt know and can‚Äôt experience the entire spectrum of intelligence.
In areas where machines exhibited super-human intelligence, humans were able to beat them by leveraging machine-specific weaknesses. For example, an amateur was able to beat a Go program that is on par with Go programs that beat world champions by studying and leveraging the program‚Äôs weaknesses.44 
### 2- Intelligence is not the solution to all problems
#### Science
Even the best machine analyzing existing data may not be able to find a cure for cancer. It may need to run real-world experiments and analyze results to discover new knowledge in most areas.
More intelligence can lead to better-designed and managed experiments, enabling more discovery per experiment. The history of research productivity should demonstrate this, but the data is quite noisy, and there are diminishing returns on research. We encounter harder problems like quantum physics as we solve simpler problems like Newtonian motion.
Finally, perfect predictions may not be possible in some domains due to the inherent randomness or immeasurability of that domain. For example, even with a wealth of data, we are not able to predict certain life outcomes with a high level of accuracy.45 
#### Economy
Intelligence is not the only ingredient for economic value generation.
  * IQ, the most commonly accepted measure of human intelligence, is not correlated with net worth for values above ~$40k (See image below):

Expand Image
!Image showing that IQ is correlated with wealth at low levels of wealth.
Figure 3: IQ is correlated with wealth at low levels of wealth.46 
Expand Image
!Graph showing that IQ is not correlated with wealth if we only focus on high levels of wealth. 
Figure 4: IQ is not correlated with wealth if we only focus on high levels of wealth. This graph is the same as the one above except that net income levels below $40k have been hidden47 
  * In the world of investing, the intelligence of a company‚Äôs team is not considered a factor of competitiveness. It is implicitly assumed that other companies can also identify intelligent strategies. Investors prefer businesses with unfair advantages that include intellectual property, scale, exclusive access to resources, etc. Most of these unfair advantages can not be replicated only with intelligence.

### 3- AGI is not possible because it is not possible to model the human brain
Theoretically, it is possible to model any computational machine, including the human brain, with a relatively simple machine that can perform basic computations and access infinite memory and time. This is the universally accepted Church-Turing hypothesis laid out in 1950. However, as stated, it requires certain difficult conditions: infinite time and memory.
Most computer scientists believe that modeling the human brain will take less than infinite time and memory. Nonetheless, there is no mathematically sound way to prove this belief, because we do not yet understand the brain well enough to precisely characterize its computational power. We will have to build such a machine!
## How can we reach AGI?
Expand Image
!Graph showing the longest tasks \(in human-equivalent time\) that each model can complete with 50% reliability. 
Figure 5: The time horizon of frontier AI models over time shows the longest tasks (in human-equivalent time) each model can complete with 50% reliability.48 
The above figure shows how AI agents‚Äô capabilities have progressed over time by measuring the longest tasks they can complete with 50% reliability. 
The key finding is that the **task length frontier models can handle has grown exponentially** , doubling roughly every seven months. This means newer models, like Claude 3.7 Sonnet and o1, can now complete tasks that would take a human nearly an hour, while older models like GPT-2 could barely handle tasks longer than a few seconds.
The shaded region reflects statistical uncertainty, but the overall trend is reliable. If this pattern continues, AI systems **could soon handle complex tasks** that take humans days or even weeks, marking a significant step toward broader autonomy and AGI-like capabilities.
### Scaling as a pathway to AGI
Leaders of frontier AI labs believe that scaling current transformer-based approaches can yield AGI, which fuels their predictions about achieving AGI in a few years.
One proposed pathway to AGI is scaling up existing architectures like transformers by increasing compute and data, while another is developing entirely new approaches. 
In support of the scaling hypothesis, a 2024 report by Epoch AI analyzed whether AI compute growth can continue through 2030. 
They identified four major constraints: power availability, chip manufacturing capacity, data scarcity, and processing latency (See Figure 6).
Despite these challenges, they argue it‚Äôs feasible to train models requiring up to 2e29 FLOPs by the end of the decade, assuming significant investments in infrastructure. 
Such advancements could produce AI systems far more capable than today‚Äôs state-of-the-art models like GPT-4, pushing us closer to AGI.49 
Expand Image
!The chart illustrates the estimated upper bounds on AI training compute by 2030 under key constraints‚Äîpower, chip production, data, and latency‚Äîwith medians ranging from 2e29 to 3e31 FLOP.
Figure 6: The chart illustrates the estimated upper bounds on AI training compute by 2030 under key constraints, power, chip production, data, and latency, with medians ranging from 2e29 to 3e31 FLOP.
### Beyond scaling: The case for new architectures
However, influential AI scientists like Yann LeCun and Richard Sutton believe that scaling large language models will not lead to human-level intelligence.50  51  They believe that new architectures or approaches are necessary for AGI.
## How can we measure whether we have reached AGI?
Large language models are blowing past new benchmarks every week, but evaluating LLMs is difficult due to issues like data poisoning and the lack of an accepted scientific definition for human-level intelligence.
These concerns are amplified by insights from recent research52 which highlight that **scaling LLMs is not a sustainable path to better performance** , especially in scientific and high-stakes domains. The authors show that:
  * LLMs exhibit **highly low scaling exponents (~0.1)** , meaning even massive increases in data or compute yield **minuscule accuracy gains**.
  * The learning power of LLMs stems from their ability to produce **non-Gaussian outputs** , but this also leads to **error pileups and brittle predictions**.
  * Traditional metrics like loss functions are **pseudo-metrics** that do not align with **true convergence or accuracy**.
  * A regime of **Degenerative AI (DAI)** may arise when models, trained on synthetic or repetitive data, accumulate errors faster than they can be corrected.

These findings call into question the reliability of standard benchmarks and underscore the need for more diverse and evolving evaluation strategies.
Old metrics like the Turing test are no match for today‚Äôs machines, and new metrics like ARC-AGI may lack the generalization capabilities of broader benchmarks.
Emerging metrics like **ARC-AGI** aim to test abstraction and generalization, but may still lack resilience to data contamination or overfitting. 
Moreover, as the paper highlights, even ‚Äúgood‚Äù loss scores may mask underlying information catastrophes due to non-Gaussian fluctuations and training instabilities.53 
### How can we track the progress of LLMs?
There are a few approaches to benchmarking to overcome these challenges:
  * Frequently updating benchmark questions. Real-life example: LiveBench
  * Using holdout sets to prevent data poisoning: AIMultiple‚Äôs benchmarks, like the AGI benchmark or ARC-AGI.

### What are approaches beyond benchmarking to determine AGI?
There are potentially strong but lagging indicators of the impact of AI, which can help identify AGI.
#### Economic growth
Microsoft CEO Satya Nadella claims that 10% growth in the developed world would indicate AGI.54 . However, his incentive is to have a delayed definition of AGI since AGI would end OpenAI and Microsoft‚Äôs exclusive partnership.55 
#### Unemployment
We expect AGI to 
  * Reduce white-collar employment to 10% of its global peak when measured as a share of people in the labor force. This should take place if labor‚Äôs share of income declines dramatically due to AI.
  * While GDP growth continues

In a world where machines are more intelligent and efficient than humans, it wouldn‚Äôt be rational to pay a human to sit in front of a computer. Therefore, we expect white collar employment to plummet while humans continue to thrive in jobs in the physical world.
Government agencies collecting labor statistics classify jobs into detailed categories, making white collar employment an easy-to-track metric.
We gathered data from the U.S. Bureau of Labor Statistics on white collar employment spanning 2019 to 2024.56 For clarity and consistency, we categorized white collar workers into the following occupational groups:
  * Architecture and Engineering Occupations
  * Business and Financial Operations Occupations
  * Computer and Mathematical Occupations
  * Healthcare Practitioners and Technical Occupations
  * Legal Occupations
  * Life, Physical, and Social Science Occupations
  * Management Occupations
  * Office and Administrative Support Occupations
  * Sales and Related Occupations

According to our analysis, the **ratio of white collar workers to total employment** has fluctuated between **45% and 48%** over this period. 
While this range suggests relative stability in the share of white collar employment so far, it is not indicative of a long-term trend, and we expect more pronounced shifts in the coming years as automation and AI adoption accelerate. For more predictions on how AI will change white collar and entry-level employment, read AI job loss. 
### Shall we even aim for AGI?
There are computer scientists who warn that focusing on AGI as the ultimate goal may distort AI research.57  Criticisms include: Creating an illusion of consensus, overfitting benchmarks, ignoring embedded social values, letting hype dictate priorities, building up ‚Äúgenerality debt‚Äù (postponing key design questions), and excluding marginalized communities and under-resourced researchers.
Specific, measurable, and transparent goals would be better for progress in AI than a vaguely defined goal like AGI.
## Mathematical reasoning behind AGI predictions
Mathematical reasoning is central to understanding and forecasting AGI timelines. Many projections are based on quantifiable trends and formal models that guide expectations about when artificial general intelligence might emerge.
### Scaling laws and compute growth
One key component of mathematical reasoning involves analyzing scaling laws. These show that model performance improves predictably with more data, parameters, and compute.
The consistent 4‚Äì5√ó annual growth in AI training compute supports forecasts that AGI may be achievable within one or two decades, assuming current trends continue.
These projections are based on empirical fits to performance curves and extrapolations, underpinned by power-law relationships, a core concept in mathematical modeling.
### Probabilistic forecasting
Researchers also apply probabilistic methods to AGI predictions. Surveys often ask experts to estimate the probability of AGI being developed by specific years, producing cumulative probability distributions. 
For example, a 50% probability by 2040 reflects consensus under uncertainty, driven by Bayesian-style updating based on observed AI progress.
This mathematical reasoning approach captures expert uncertainty without requiring precise dates, allowing ongoing revision as new data becomes available.
### Theoretical foundations
These forecasts are based on theoretical elements of mathematical reasoning, including the Church-Turing thesis, which implies that human cognition can be simulated by machines, and concepts like Kolmogorov complexity, which relate intelligence to the compressibility of information.
While such theories do not guarantee AGI, they provide a framework for thinking about its possibility and the computational requirements involved.
## More about Artificial General Intelligence
Videos from leading AI scientists:
### David Silver, Principal Research Scientist at Google DeepMind
He explains that Artificial General Intelligence (AGI) refers to AI systems capable of learning and excelling at a wide range of tasks; much like humans who can become experts in diverse fields such as science, music, or sports.
Unlike narrow AI limited to a single function, AGI aspires to mirror human adaptability and general problem-solving ability. 
He notes that while AGI is a long-term goal, reaching true human-level intelligence will likely require several breakthroughs and will develop gradually over time (See the video below).
David Silver of DeepMind describes AGI as AI with human-like versatility across tasks, noting it will require multiple breakthroughs and will develop gradually over time.
### Ilya Sutskever, co-founder and Chief Scientist of OpenAI
In the TED Talk ‚ÄúThe Exciting, Perilous Journey Toward AGI,‚Äù he explores the rapid progress toward Artificial General Intelligence (AGI).
He predicts AGI could emerge within the next 5 to 10 years, though he acknowledges uncertainty in this timeline. 
Sutskever highlights both the immense potential and the profound risks of AGI, stressing the need to align its development with human values. Despite the challenges, he is optimistic that humanity can safely guide this powerful technology (See the video below).
In his TED Talk, Ilya Sutskever predicts AGI could arrive within 5‚Äì10 years, emphasizing its transformative potential and the urgent need to align it with human values to ensure a safe future.
### Ray Kurzweil, computer scientist and entrepreneur
He reflects on over six decades of AI progress, tracing humanity‚Äôs ability to build intelligence-enhancing tools, from primitive implements to large language models.
He also predicts that Artificial General Intelligence will arrive by 2029, leading to technological singularity by 2045. He highlights exponential advances in computing power, medicine, and biotechnology.
He also forecasts breakthroughs like AI-generated cures, digital clinical trials, and longevity escape velocity, where scientific progress could extend life indefinitely (See the video below).
In his TED Talk, Ray Kurzweil predicts AGI by 2029 and a technological singularity by 2045, envisioning a future where exponential AI advances revolutionize medicine and extend human longevity.
### Yann LeCun, Turing award recipient
See why LLMs can not give us human-level intelligence and the latest AI approaches to get there:
## üí°Conclusion
Predictions for AGI have shifted notably in recent years. While earlier surveys placed its arrival closer to 2060, recent forecasts, especially from entrepreneurs, suggest it could emerge as early as 2026‚Äì2035.
This change is fueled by rapid advances in large language models and growing compute power. Yet, despite these gains, today‚Äôs AI still lacks the general flexibility and autonomy associated with human-level intelligence.
Experts remain divided on how AGI will be achieved; some believe scaling current architectures will be enough, while others argue that new methods are needed.
Key challenges include high resource demands, unclear benchmarks, and unresolved ethical concerns. AGI may be closer than ever, but its arrival still hinges on both technical breakthroughs and careful oversight.
## FAQ
### What is singularity?
### What is AGI (Artificial General Intelligence)?
### What is Superintelligence?
### What is AMI (Advanced Machine Intelligence)?
## Reference Links
[1.[2311.02462] Levels of AGI for Operationalizing Progress on the Path to AGI](https://research.aimultiple.com/<https:/arxiv.org/abs/2311.02462>)2.https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-Digital-3.7.25.pdf[3.2023 Expert Survey on Progress in AI [AI Impacts Wiki]](https://research.aimultiple.com/<https:/wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai>)4.2022 Expert Survey on Progress in AI ‚Äì AI Impacts[5.[2206.04132] Forecasting AI Progress: Evidence from a Survey of Machine Learning Researchers](https://research.aimultiple.com/<https:/arxiv.org/abs/2206.04132>)6.When Will We Reach the Singularity? - A Timeline Consensus from AI Researchers (AI FutureScape 1 of 6)7.AI timelines: What do experts in artificial intelligence expect for the future? - Our World in Data[8.[1705.08807] When Will AI Exceed Human Performance? Evidence from AI Experts](https://research.aimultiple.com/<https:/arxiv.org/abs/1705.08807>)9.https://nickbostrom.com/papers/survey.pdf10.https://sethbaum.com/ac/2011_AI-Experts.pdf11.OpenAI Ramps Up Robotics Work in Race Toward AGI | WIREDWIRED[12.[2303.12712] Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://research.aimultiple.com/<https:/arxiv.org/abs/2303.12712>)13.https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR_ArmEBrief_V12_final.pdf14.AGI's Last Bottlenecks | AI FrontiersAI Frontiers15.https://www.agidefinition.ai/paper.pdf16.When will the first weakly general AI system be devised, tested, and publicly announced?17.When will an AI first pass a long, informed, adversarial Turing test?18.As of July 1, 2022, when will top forecasters expect the first Artificial General Intelligence to be developed and demonstrated?19.When Will the First General AI Be Announced?20.Dr. Eric Schmidt - YouTube21.Tesla's Musk predicts AI will be smarter than the smartest human next year | ReutersReuters22.https://www.youtube.com/watch?v=Xywqm0vlUxk23.SoftBank, OpenAI to Offer AI Services in Japan - WSJThe Wall Street Journal24.Nvidia CEO says AI could pass human tests in five years | ReutersReuters25.The Singularity Is Near: When Humans Transcend Biology: Kurzweil, Ray: 8601405784551: Amazon.com: Books26.If Ray Kurzweil Is Right (Again), You‚Äôll Meet His Immortal Soul in the Cloud | WIREDWIRED27.The "Father of Artificial Intelligence" Says Singularity Is 30 Years AwayFuturism28.DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business InsiderBusiness Insider29.The brief history of artificial intelligence: the world has changed fast ‚Äî what might be next? - Our World in Data30.The "Father of Artificial Intelligence" Says Singularity Is 30 Years AwayFuturism31.Geoff Hinton: On Radiology - YouTube32.Artificial general intelligence - WikipediaContributors to Wikimedia projects33.Artificial general intelligence - WikipediaContributors to Wikimedia projects34.A guide to why advanced AI could destroy the world | VoxVox35.Brain‚Äìcomputer interface - WikipediaContributors to Wikimedia projects36.OpenAI claims new GPT-5 model boosts ChatGPT to ‚ÄòPhD level‚Äô BBC News37.GPT-5: has AI just plateaued?38. Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad - Google DeepMind 39.Training compute of frontier AI models grows by 4-5x per year | Epoch AI40.AlphaGo Zero - WikipediaContributors to Wikimedia projects41.Moore's law - WikipediaContributors to Wikimedia projects42.I think the phrase AGI should be retired and replaced by "human-level AI". There is no such thing as AGI. Even human intelligence is very specialized. We do not realize that human intelligence is‚Ä¶ | Yann LeCun | 125 comments43.A talk I gave at MIT recently. | Yann LeCun | 139 comments44.Subscribe to readFinancial Times45.Measuring the predictability of life outcomes with a scientific mass collaboration | PNAS46.IQ is largely a pseudoscientific swindle (Argument Closed) | by Nassim Nicholas Taleb | INCERTO | MediumINCERTO47.ScienceDirect48.https://arxiv.org/pdf/2503.1449949.Can AI scaling continue through 2030? | Epoch AI50.Unsupported browser51.Richard Sutton ‚Äì Father of RL thinks LLMs are a dead end - Dwarkesh Podcast | Podcast on Spotify52.https://www.arxiv.org/pdf/2507.1970353.https://www.arxiv.org/pdf/2507.1970354.Inside Microsoft‚Äôs AI Bet: Satya Nadella on Leadership, Innovation and the Future - YouTube55.OpenAI, Microsoft Rift Hinges on How Smart AI Can Get - WSJThe Wall Street Journal56.Occupational Employment and Wage Statistics (OEWS) Tables : U.S. Bureau of Labor Statistics57.https://arxiv.org/abs/2502.03689
Principal Analyst
!Cem Dilmegani
Cem Dilmegani
Principal Analyst
Follow On
Cem has been the principal analyst at AIMultiple since 2017. AIMultiple informs hundreds of thousands of businesses (as per similarWeb) including 55% of Fortune 500 every month.Cem's work has been cited by leading global publications including Business Insider, Forbes, Washington Post, global firms like Deloitte, HPE and NGOs like World Economic Forum and supranational organizations like European Commission. You can see more reputable companies and resources that referenced AIMultiple.Throughout his career, Cem served as a tech consultant, tech buyer and tech entrepreneur. He advised enterprises on their technology decisions at McKinsey & Company and Altman Solon for more than a decade. He also published a McKinsey report on digitalization.He led technology strategy and procurement of a telco while reporting to the CEO. He has also led commercial growth of deep tech company Hypatos that reached a 7 digit annual recurring revenue and a 9 digit valuation from 0 within 2 years. Cem's work in Hypatos was covered by leading technology publications like TechCrunch and Business Insider. Cem regularly speaks at international technology conferences. He graduated from Bogazici University as a computer engineer and holds an MBA from Columbia Business School.
View Full Profile
Researched by
!Sƒ±la Ermut
Sƒ±la Ermut
Industry Analyst
Follow On
Sƒ±la Ermut is an industry analyst at AIMultiple focused on email marketing and sales videos. She previously worked as a recruiter in project management and consulting firms. Sƒ±la holds a Master of Science degree in Social Psychology and a Bachelor of Arts degree in International Relations.
View Full Profile
## Comments 12
### Share Your Thoughts
Your email address will not be published. All fields are required.
!Harper Ford
Harper Ford
Sep 07, 2023 at 15:32
Does anyone know when this article was first published? I want to do a comparison of predictions vs reality for a project.
Reply
!Bardia Eshghi
Bardia Eshghi
Sep 11, 2023 at 05:04
Hi Harper. The article was first published in mid-2017. But it's undergone constant updates since then to reflect the latest developments. Good luck with your project and let us know if we can help further!
Reply
!Yuvan Mohan
Yuvan Mohan
Apr 20, 2022 at 14:28
I think we are far away from the point of singularity. It is not only that intelligence is multi dimensional, but also what is deemed as being intelligent (e.g., IQ, EQ) changes with time. People also change with time. So what is that point of singularity may change.
Reply
!Bardia Eshghi
Bardia Eshghi
Aug 23, 2022 at 07:52
Hello, Yuvan. Thank you for your feedback.
Reply
!David Wood
David Wood
Mar 26, 2022 at 22:50
Hello, Achieving the singularity from where we are now is relatively a simple jump, it is just time and advancements combined with a team somewhere who is dedicated to it and has the money to pull it off. The missing part of the equation would be asking the question "what is consciousness?" and understanding that. Then, understanding how to model that with non-biological machinery even at small levels, like modeling the consciousness of an amoeba or more advanced things like snakes and squirrels. Then if we know for certain what it is and how to model it, just run an adaptive evolution algorithm on itself, modeling out all of the processes in human cognition until it can beat them everywhere. Then, allow it to simply rebuild itself to continuously improve. The problem currently preventing this, is that human beings have no idea what consciousness is at all. It is a great mystery. One person thinks it is in the brain. Another thinks the brain is like a tuning fork, channeling the consciousness from somewhere else. It is a great mystery in science. When this problem is solved, then machine consciousness can be built most likely, depending on what it actually is. If consciousness is something weird, such as "human beings have spirits in other dimensions that are planned for their bodies by a supreme being. The brain creates a quantum resonant frequency that links it together with this already conscious entity, and then several universes are interacting simultaneously to create the actual experience of being self aware and sentient" well then, it will be very difficult to design a machine that does that same thing. It is more likely that we figure out how to model the resonance in the brain and then transfer an already existing consciousness of an animal or a human into a machine and keep it going, if that even makes any sense at all. However, maybe that's not how it works, and it is something simple like the holographic connection of energy patterns fluctuating in the mind - this can be modeled and a machine can be built that does these sorts of things with much more efficiency. Right now the mystery of the problem is consciousness itself. Hope that helps. I really enjoyed the robot soccer tournament. I also feel like a superhero at soccer now.
Reply
!Grant Castillou
Grant Castillou
Mar 15, 2022 at 17:28
It's becoming clear that with all the brain and consciousness theories out there, the proof will be in the pudding. By this I mean, can any particular theory be used to create a human adult level conscious machine. My bet is on the late Gerald Edelman's Extended Theory of Neuronal Group Selection. The lead group in robotics based on this theory is the Neurorobotics Lab at UC at Irvine. Dr. Edelman distinguished between primary consciousness, which came first in evolution, and that humans share with other conscious animals, and higher order consciousness, which came to only humans with the acquisition of language. A machine with primary consciousness will probably have to come first. The thing I find special about the TNGS is the Darwin series of automata created at the Neurosciences Institute by Dr. Edelman and his colleagues in the 1990's and 2000's. These machines perform in the real world, not in a restricted simulated world, and display convincing physical behavior indicative of higher psychological functions necessary for consciousness, such as perceptual categorization, memory, and learning. They are based on realistic models of the parts of the biological brain that the theory claims subserve these functions. The extended TNGS allows for the emergence of consciousness based only on further evolutionary development of the brain areas responsible for these functions, in a parsimonious way. No other research I've encountered is anywhere near as convincing. I post because on almost every video and article about the brain and consciousness that I encounter, the attitude seems to be that we still know next to nothing about how the brain and consciousness work; that there's lots of data but no unifying theory. I believe the extended TNGS is that theory. My motivation is to keep that theory in front of the public. And obviously, I consider it the route to a truly conscious machine, primary and higher-order. My advice to people who want to create a conscious machine is to seriously ground themselves in the extended TNGS and the Darwin automata first, and proceed from there, by applying to Jeff Krichmar's lab at UC Irvine, possibly. Dr. Edelman's roadmap to a conscious machine is at https://arxiv.org/abs/2105.10461
Reply
!Isaac
Isaac
Nov 06, 2021 at 07:01
I think Patrick Winston was joking when he said 20 years. From the linked quote: "I was recently asked a variant on this question. People have been saying we will have human-level intelligence in 20 years for the past 50 years. My answer: I‚Äôm ok with it. It will be true eventually." "Forced into a corner, with a knife at my throat, I would say 20 years, and I say that fully confident that it will be true eventually."
Reply
!Cem Dilmegani
Cem Dilmegani
Nov 06, 2021 at 11:22
Great point! We should have read the source more carefully. I tried to explain his point better in the article.
Reply
!Elisa
Elisa
Aug 31, 2021 at 05:52
I have the impression that the nerds that make this kind of prediction (replicate human brain) know a whole lot about computer programming but are ignorant about neuroscience/psychology. We are nor even scratching the surface about primary phenomenon, such as counsciousness / unconsciousness. How do you claim that you can replicate something that we are still far from understanding how it works?
Reply
!Cem Dilmegani
Cem Dilmegani
Sep 19, 2021 at 13:41
Thank you for the comment. True, better understanding of the mind would help AGI research.
Reply
!Lulu
Lulu
Aug 25, 2021 at 15:47
mmm... I'm not sure we can reach to this point: "benevolence of intelligent machines" Emotions and Feelings are there to guide our actions, to improve ourselves and to make a better world, can we make a machine to feel guilt of being smarter than us??
Reply
!Michael Hannon
Michael Hannon
Apr 02, 2021 at 02:15
Saying human intelligence is fixed ignores that as we learn more about how the human brain works we may learn how to expand its capability's ie through some form of enhanced learning, targeted drugs, gene therapy, electro stimulation and not just direct brain computer connections being the only potential for doing this. More so currently hampered by our lack of understanding even the language you use has an effect on your cognitive ability's its one of the reasons deaf people were called dumb was the occurrence of language deprivation and how it negatively effected neurodevelopment it was a major problem when deaf children were forced to lip read instead of using sign language . But we will need more powerful AIs to achieve an understanding of our brains
Reply
!Vyn
Vyn
Jan 09, 2021 at 16:07
People who say AGI will be here in 2060 are idiots and don't understand the flow of technology you'll see
Reply
!Chris
Chris
May 24, 2021 at 15:45
@Vyn What do you mean? Do you mean to say it will take way before or way after 2060?
Reply
!Cem Dilmegani
Cem Dilmegani
Jan 10, 2021 at 16:05
Thanks! I'll be quite happy if I get to see 2060
Reply
!Kutay Tezcan
Kutay Tezcan
Aug 30, 2020 at 13:33
Intelligent doesn't solve our all problems maybe yes but certainly its essential and more intelligent you are faster you solve problems. If you are a chimp you can not even pour water to a glass. You do not even know what glass is used for. Yes if you are human being you still need to get up and grab the glass but intellegence is essential. I do not think human brain is impossible to create in a lab. I think earth is a lab. Anything found in nature can be replicate in the lab.
Reply
!Magnus RC Wootton
Magnus RC Wootton
Aug 22, 2020 at 21:46
if P=NP then the singularity may happen also. Saying the human brain is impossible to recreate I dont agree with, but to say its intractable probably is approximately true. So P=NP, if you could solve that mystery (which is the millenial prize funnily) with an intractable calculation, that could make all the magic happen as well.
Reply
!Cem Dilmegani
Cem Dilmegani
Aug 23, 2020 at 07:44
Thanks for the comment. Most computer scientists working on AI or machine learning would agree that it is possible to replicate human brain's capabilities.
Reply
!Jannes
Jannes
May 16, 2019 at 07:40
The claim that "humans contribute most to the biomass" on the planet is likely to be wrong. Check out this paper for a careful estimation: https://www.pnas.org/content/115/25/6506
Reply
!AIMultiple
AIMultiple
May 27, 2019 at 17:42
Thank you! That was insightful. Biology is not my strong suit, I should stick to computer science.
Reply
!B
B
Jul 01, 2020 at 09:00
@AIMultiple Humble response, and great article. Thanks a ton :)
Reply
!Cem Dilmegani
Cem Dilmegani
Jul 20, 2020 at 20:29
@B Thanks!
Reply
In This Article
Artificial General Intelligence timeline
Learning from past over-optimism in AI predictions
Understand what singularity is
Why experts believe AGI is inevitable: Key arguments & evidence
Why do some experts believe that we will not reach AGI?
How can we reach AGI?
How can we measure whether we have reached AGI?
Mathematical reasoning behind AGI predictions
More about Artificial General Intelligence
Conclusion
FAQ
We follow ethical norms & our process for objectivity. AIMultiple's customers in AI Foundations include Creatio, nexos.ai, Weights & Biases.
[](https://research.aimultiple.com/<https:/www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fresearch.aimultiple.com%2Fartificial-general-intelligence-singularity-timing%2F>)[](https://research.aimultiple.com/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fresearch.aimultiple.com%2Fartificial-general-intelligence-singularity-timing%2F>)
Summarize This Research

## Next to Read
AI AgentsOct 24Building AI Agents with Anthropic's 6 Composable PatternsAI AgentsOct 27AI Agent Deployment: Steps and Challenges in 2026Survey ReviewsSep 4Comparison of Top 5 AI Survey Tools in 2026
AI CodingOct 108 AI Code Models Benchmarked: LMC-Eval in 2026AI FoundationsNov 12AGI Benchmark: Can AI Generate Economic Value in 2026Agentic AI FrameworksNov 26Compare 50+ AI Agent Tools in 2026
!line
