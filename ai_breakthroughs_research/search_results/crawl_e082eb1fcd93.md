---
title: "State of AI: Enterprise Adoption & Growth Trends | Databricks Blog"
source: https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends
date: 2023-02-01
description: "The state of AI in 2024 shows enterprise adoption accelerating with 11x more production models, 377% growth in vector databases, and 76% of organizations choosing open source LLMs. Learn how highly re"
word_count: 4093
---

Skip to main content
Contents in this story
Share this post
  * [](https://www.databricks.com/blog/<https:/www.linkedin.com/shareArticle?mini=true&url=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends&summary=&source=>)
  * [](https://www.databricks.com/blog/<https:/twitter.com/intent/tweet?text=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends>)
  * [](https://www.databricks.com/blog/<https:/www.facebook.com/sharer/sharer.php?u=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends>)

Keep up with us
Subscribe
Generative AI entered mainstream conversations just 18 months ago, yet it's already transforming how organizations operate. The question business leaders ask now isn't whether to invest in artificial intelligence—it's how to deploy AI effectively and at scale.
Our comprehensive state of AI report reveals a dramatic shift from experimentation to production deployment. Drawing on aggregated, anonymized data from more than 10,000 global customers—including over 300 Fortune 500 companies—this analysis provides a snapshot of how organizations are prioritizing data and AI initiatives across industries.
The findings are striking: organizations put 11 times more AI models into production this year compared to last year. Vector databases supporting retrieval augmented generation (RAG) applications grew 377% year-over-year. And 76% of companies using large language models (LLMs) are choosing open source models, often alongside proprietary alternatives.
This report examines machine learning adoption trends, the evolution to generative AI, industry-specific use cases, and the tools reshaping enterprise AI strategies. The data spans February 1, 2023, to March 31, 2024, with year-over-year comparisons showcasing the rapid acceleration of AI capabilities across the business landscape.
## Enterprise AI Adoption Accelerates
The state of AI today marks a decisive turning point: companies are moving beyond pilots and proofs of concept to deploy artificial intelligence in production environments. This transition represents years of groundwork finally yielding measurable business value.
Data reveals that 56% more companies are logging experimental AI models compared to a year ago. But the real story lies in production deployment—210% more organizations are now registering models for production use. This indicates that many companies focused on experimenting last year have crossed the threshold into operational AI systems.
The volume of AI models has grown substantially. Organizations registered 1,018% more models this year, far outpacing the 134% growth in experimental models logged. At the company level, the average organization registered 261% more models and logged 50% more experiments this year. This dramatic shift signals that AI adoption has reached critical mass across enterprises.
### Highly Regulated Industries Lead the Charge
Contrary to expectations, highly regulated industries are among the fastest AI adopters. Financial Services demonstrates the strongest commitment to AI technologies, with the highest average GPU usage per company and 88% growth in GPU utilization over just six months. This regulated industry is leveraging AI for business-critical use cases including fraud detection, wealth management, and investor analytics.
Healthcare & Life Sciences has emerged as another surprise early adopter. The industry has the highest proportion of Python library usage devoted to natural language processing at 69%, reflecting AI's potential to accelerate drug discovery, analyze clinical research, and improve commercial effectiveness. Healthcare generates 30% of the world's data volume—growing faster than any other industry—making AI tools essential for extracting insights from this massive dataset.
Manufacturing & Automotive leads the adoption of foundation model APIs, using open source LLMs for supply chain optimization, quality control, and operational efficiency improvements. The industry saw 148% year-over-year growth in NLP adoption, the highest among all sectors analyzed.
## Organizations Become 3x More Efficient at Deploying AI Models
While model development and experimentation remain crucial, the ultimate measure of AI success is production deployment. Companies are becoming significantly more efficient at getting models into production, spending fewer resources on experimental models that never deliver real-world value.
The ratio of experimental-to-production models serves as a key efficiency metric. In February 2023, organizations logged 16 experimental models for every one model registered for production. By March 2024, this ratio dropped sharply to 5-to-1—a 3x improvement in efficiency. This means companies are testing more rigorously, selecting better model candidates, and streamlining their deployment pipelines.
This efficiency gain translates directly to business value. Each production model can drive revenue, reduce costs, or improve customer experience. The acceleration in production deployments suggests organizations have matured their AI operations, developing the infrastructure, governance, and processes needed to move quickly from concept to production.
### Industry Efficiency Benchmarks Reveal Different AI Strategies
Different industries approach AI with distinct risk profiles and strategic goals, reflected in their experimentation-to-production ratios.
Retail & Consumer Goods achieved the highest efficiency, reaching a ratio of 4-to-1—putting 25% of their experimental models into production. This industry has long been an AI early adopter due to competitive pressure and high consumer expectations for personalized experiences.
Financial Services, while the most testing-intensive industry, saw the sharpest efficiency improvement. The sector started 2023 logging 29 experiments for every one model registered. By March 2024, they achieved a 10-to-1 ratio—nearly 3x more efficient. The higher stakes in regulated industries necessitate lengthy testing cycles, but even with rigorous compliance requirements, Financial Services dramatically improved its production velocity.
Public Sector & Education, Healthcare & Life Sciences, and Technology & Communications all demonstrated steady efficiency improvements, indicating that the tools and practices enabling faster AI deployment are spreading across all sectors.
## NLP Emerges as the Top AI Use Case Across Industries
Natural language processing dominates the artificial intelligence landscape. For the second consecutive year, NLP is the top data science and machine learning application, with 50% of specialized Python libraries devoted to NLP use cases.
This dominance makes sense: unstructured data is ubiquitous across industries and regions, making NLP techniques essential to derive meaning. From analyzing customer feedback and processing legal documents to powering chatbots and extracting insights from medical records, NLP unlocks value from text data at scale. Generative AI represents one of the most significant NLP applications, driving much of the recent surge in adoption.
NLP isn't just the most widely used application—it's also experiencing the fastest growth at 75% year-over-year. This acceleration reflects both the maturation of transformer-based models and the explosion of GenAI applications built on large language models.
### Industry-Specific NLP Applications Drive Growth
Every industry is investing heavily in NLP, but adoption patterns reveal sector-specific priorities:
Healthcare & Life Sciences has the highest concentration of NLP usage at 69% of Python libraries. The industry applies NLP to analyze clinical research, accelerate novel drug development, and enhance sales and marketing effectiveness. Time series analysis—supporting patient risk predictions and disease forecasting—grew 115% year-over-year in this sector, reflecting its critical role in pandemic response and epidemiological research.
Manufacturing & Automotive recorded the largest NLP growth at 148% year-over-year. These organizations use NLP to analyze customer feedback, monitor quality control systems, power conversational interfaces, and improve operational efficiency. The technology helps manufacturers process the growing volume of sensor data and maintenance logs generated by connected equipment.
Public Sector & Education followed closely with 139% NLP growth. Applications range from analyzing citizen feedback and automating document processing to supporting emergency response planning and disaster management through geospatial analysis.
The consistency of NLP growth across all industries confirms that natural language processing has become a foundational AI capability, not a specialized tool for tech-forward companies.
## Retrieval Augmented Generation and Vector Databases Transform Enterprise AI
The evolution to generative AI marks a new phase in enterprise artificial intelligence. While large language models like GPT-4 went mainstream less than two years ago and demonstrated remarkable capabilities, enterprises quickly discovered their limitations. Stand-alone LLMs can provide unreliable information, generate hallucinations, and lack the domain-specific knowledge organizations need.
This reality is driving companies toward retrieval augmented generation (RAG), which enables organizations to customize LLMs with proprietary data. RAG finds relevant documents and data to provide context for the LLM, resulting in more accurate responses grounded in enterprise knowledge.
The data confirms this trend: 70% of companies leveraging generative AI are using tools, retrieval systems, and vector databases to augment base models rather than relying on off-the-shelf LLMs alone.
### Vector Database Adoption Explodes
Vector databases generate representations of predominantly unstructured data, enabling fast similarity searches essential for RAG applications. The entire vector database category grew 377% year-over-year—the fastest growth among all LLM-related technologies.
Since the public preview of Databricks Vector Search in December 2023, vector database adoption accelerated further with 186% growth in just over three months. This exponential growth suggests companies are moving rapidly to build RAG applications that integrate enterprise data with large language models.
The architecture is becoming standard: organizations embed their documents and data as vectors, store them in specialized vector databases, then retrieve relevant context when users query the LLM. This pattern allows companies to maintain data governance, incorporate real-time information, and reduce hallucinations without the cost and time requirements of fine-tuning or pretraining custom models.
## The Modern AI Tools Stack Takes Shape
Last year, customers jumped into LLMs primarily through SaaS offerings like OpenAI's GPT models. That trend continues—usage of SaaS LLMs grew 178% year-over-year. But the data reveals increasing sophistication as organizations take more control over their AI implementations.
**LangChain's Meteoric Rise:** The open source LLM toolchain jumped into the top four most-used data and AI products in less than one year of integration. LangChain enables developers to build prompt interfaces, integrate external systems, and orchestrate complex workflows around language models. Its rapid adoption reflects the growing demand for tools that help organizations build proprietary AI applications.
**Hugging Face Transformers Jumps to #2:** Hugging Face Transformers rose from fourth to second place among the most popular products. Organizations use the platform's pretrained transformer models together with enterprise data to build and fine-tune foundation models. This supports the broader RAG trend, as companies customize models for specific use cases.
**Plotly Dash Maintains Top Position:** For more than two years, Plotly Dash has held the #1 spot. The low-code platform enables data scientists to build, scale, and deploy data applications quickly—reflecting the growing pressure on practitioners to deliver production-grade applications faster.
The prominence of three data integration products in the top 10—dbt (data transformation), Fivetran (pipeline automation), and Great Expectations (data quality)—indicates companies recognize that high-quality AI requires trusted datasets as a foundation.
## 76% of Organizations Choose Open Source LLMs
One of the biggest shifts in the state of AI is the preference for open source large language models. Among companies using LLMs, 76% are choosing open source options, often running them alongside proprietary models. This represents a significant evolution in enterprise AI strategy, driven by considerations of cost, performance, latency, and control.
Open source LLMs offer several advantages: organizations can customize them for specific use cases, maintain data sovereignty, avoid vendor lock-in, and reduce inference costs. The tradeoff lies in balancing model size, performance, and operational requirements.
### The Model Size Debate: Smaller Often Wins
Analysis of Meta Llama and Mistral—the two most popular open source model families—reveals a clear preference for smaller models. Across all users, 77% choose models with 13 billion parameters or fewer, compared to larger 70B+ parameter models.
The combined usage of Meta Llama 2's two smallest models (7B and 13B parameters) significantly exceeds the largest Meta Llama 2 70B model. This pattern suggests organizations care deeply about cost and latency. Smaller models run faster, require less compute infrastructure, and cost substantially less to operate—critical factors when serving millions of inference requests.
### Rapid Adoption of New State-of-the-Art Models
The open source AI ecosystem moves quickly, with new models getting rapid adoption. Meta Llama 3 launched on April 18, 2024. Within its first week, organizations already started leveraging it over other models and providers. Just four weeks after launch, Llama 3 accounted for 39% of all open source LLM usage—a remarkable adoption velocity.
This rapid model switching demonstrates that enterprises are actively monitoring AI research, benchmarking new releases, and quickly integrating improvements. The pattern suggests most organizations have developed deployment infrastructure flexible enough to swap models as better options emerge.
The fluidity of the open LLM space contrasts with proprietary models, where organizations are more locked into specific API endpoints and pricing structures. This flexibility represents a strategic advantage for companies investing in open source AI capabilities.
## AI Agents Begin Acting in Production Environments
Beyond simple question-answering, artificial intelligence agents are emerging as systems that can perceive their environment, make decisions, and take actions to achieve specific goals. This represents a fundamental evolution in how organizations deploy AI—from passive tools to active participants in business processes.
The data reveals growing investment in the infrastructure required for agentic AI. Real-time model serving—which enables AI systems to make immediate predictions or take actions based on incoming data—is seeing accelerating adoption. Companies are shifting to serverless model serving that automatically scales to meet demand, reducing costs while enabling the fast response times agentic systems require.
### Serverless Infrastructure Supports Real-Time AI
Serverless architectures have become essential for deploying AI agents that interact with users and systems in real-time. Organizations can build applications ranging from personalized recommendations to fraud detection without managing complex infrastructure.
Financial Services leads serverless adoption with 131% growth over six months. Real-time prediction capabilities strengthen market analysis, enable instant fraud detection, and power algorithmic trading systems where milliseconds matter.
Healthcare & Life Sciences grew serverless usage 132% over six months, moving from fourth to second place year-over-year. The industry experiences significant fluctuations in data processing requirements, especially when dealing with large datasets like genomic data or medical imaging. Serverless infrastructure handles these variable workloads efficiently.
The investment in real-time serving infrastructure signals that organizations are moving beyond batch processing and analytics toward AI systems that act autonomously in production environments—a key milestone in the physical world applications of AI.
## Highly Regulated Industries Lead AI Governance Adoption
As AI adoption accelerates, governance becomes critical. Organizations need frameworks to develop and maintain AI products while adhering to security standards, compliance requirements, and ethical guidelines. This is particularly crucial in highly regulated industries where data privacy, model explainability, and audit trails carry legal weight.
Unified governance solutions that span all data and AI assets make it easier for organizations to train and deploy models on private data while maintaining control. According to Gartner, AI trust, risk, and security management rank among the top technology trends factoring into business decisions in 2024.
### Financial Services Sets the Governance Standard
Financial Services leads the adoption of unified data and AI governance platforms. Regulatory compliance is deeply embedded in the culture of financial institutions, and that discipline extends to AI systems. Survey data from MIT Technology Review Insights indicates financial institutions expect 74% investment growth in data management and infrastructure through 2025, compared with 52% for other industries.
This governance-first approach enables Financial Services to move quickly on AI adoption while maintaining the controls required by regulators. The industry's success demonstrates that rigorous governance doesn't slow innovation—it provides the foundation for responsible scaling.
Healthcare & Life Sciences, another heavily regulated sector, follows closely in governance adoption. The industry must navigate HIPAA compliance, patient privacy requirements, and FDA regulations for AI-enabled medical devices. Unified governance platforms help organizations maintain compliance while leveraging AI to improve patient outcomes.
## The AI Infrastructure Challenge: Compute, Costs, and Scale
The infrastructure requirements for artificial intelligence—particularly large language models—differ dramatically from traditional applications. Training and serving LLMs requires specialized hardware, primarily GPUs that can parallel-process millions of tasks simultaneously. This creates both opportunities and challenges as organizations scale their AI initiatives.
Analysis of CPU versus GPU usage reveals how industries are allocating resources between classic machine learning (which typically uses CPUs) and LLM-based applications (which require GPUs). Financial Services dominates GPU usage, with by far the highest average per company and the fastest growth at 88% over six months. This substantial investment in compute infrastructure reflects the industry's commitment to generative AI applications.
### Balancing Performance and Cost at Scale
As AI adoption grows, compute costs become a major consideration. Organizations must balance model performance against infrastructure expenses, leading many to prefer smaller, more efficient models. The 77% preference for models with 13B parameters or fewer reflects this cost consciousness.
Private investment in AI infrastructure continues flowing, with companies recognizing that compute capabilities provide competitive advantage. However, organizations are also seeking efficiency gains through techniques like model quantization, distillation, and optimized serving infrastructure.
The serverless adoption trend addresses cost concerns by enabling organizations to pay only for actual usage rather than maintaining dedicated infrastructure. This approach helps companies manage the variable costs of AI as they scale from hundreds to millions of inference requests.
## AI's Impact on Productivity, Jobs, and the Workforce
The debate around artificial intelligence's impact on employment and workforce size generates strong opinions and considerable anxiety. Survey results paint a nuanced picture: most organizations report productivity gains from AI tools while also grappling with questions about workforce transformation.
The data suggests AI is amplifying human capabilities rather than simply replacing workers. Organizations using AI report measurable productivity improvements across knowledge work, customer service, software development, and analytical tasks. AI agents handle routine queries, generate first drafts, and surface insights from data—allowing employees to focus on higher-value activities requiring creativity, judgment, and interpersonal skills.
### The Productivity-Workforce Gap
Three-quarters of organizations report productivity gains from AI adoption, yet concerns about displacement persist. The reality emerging from early implementations is more complex than simple job elimination. Many companies are reallocating human talent to new roles, using AI to handle growing workloads without proportional headcount increases, and discovering entirely new capabilities enabled by AI augmentation.
Manufacturing provides an example: AI-powered quality control systems don't eliminate inspectors but enable them to focus on exception handling and process improvement rather than repetitive visual inspections. In Financial Services, AI agents handle routine customer inquiries while human advisors concentrate on complex financial planning requiring empathy and nuanced understanding.
The workforce transformation is real, but the outcome depends heavily on how organizations manage the transition. Companies investing in reskilling, creating new roles that leverage AI tools, and focusing on human-AI collaboration report stronger outcomes than those pursuing pure cost reduction through headcount elimination.
## The Future of AI: What to Expect Next Year
Looking ahead, several trends will shape the next phase of artificial intelligence adoption. The shift from experimentation to production will continue accelerating as more organizations develop the operational capabilities needed to deploy AI at scale. We expect efficiency gains to compound, with companies becoming even more adept at selecting and deploying the right models for specific use cases.
Open source AI will likely capture larger share of enterprise deployments. As models continue improving rapidly—as demonstrated by Meta Llama 3's fast adoption—organizations that built flexible infrastructure will gain advantage. The debate between open source and proprietary models will increasingly focus on specific use case requirements rather than blanket preferences.
Agentic AI systems will move from early experiments to widespread production deployment. As organizations gain confidence with retrieval augmented generation and real-time serving, they'll build more sophisticated compound AI systems that can act autonomously within defined parameters. This evolution will drive growth in supporting technologies like vector databases, orchestration frameworks, and monitoring tools.
The gap between AI leaders and peers will likely widen. Organizations that invested early in data infrastructure, governance frameworks, and AI capabilities are realizing compound returns as each new model and technique builds on their foundation. Companies still in early stages face the challenge of catching up while the technology continues advancing rapidly.
Highly regulated industries will continue surprising skeptics with aggressive AI adoption. Financial Services, Healthcare & Life Sciences, and Public Sector organizations have demonstrated that robust governance enables rather than hinders innovation. Their success provides a playbook for other industries navigating compliance requirements.
### Key Challenges on the Horizon
Despite the progress, organizations face persistent challenges. Compute infrastructure costs remain high, particularly for companies operating at scale. Most cases of AI deployment reveal gaps between prototype performance and production reliability, requiring significant engineering effort to bridge.
Data quality and integration continue plaguing AI initiatives. The prominence of data integration tools in our top products reflects ongoing work to build the trusted datasets AI requires. Organizations cannot simply bolt AI onto messy, siloed data—they must invest in data management as a prerequisite for AI success.
Transparency and explainability remain critical concerns, particularly in regulated industries. As AI systems make more consequential decisions, organizations need clear audit trails and the ability to explain model behavior. This requirement drives investment in AI governance and monitoring solutions.
The talent gap persists, with demand for AI practitioners far exceeding supply. Organizations are addressing this through training programs, low-code tools that democratize AI development, and partnerships with academic institutions. However, building effective AI teams remains one of the most common barriers to scaling AI initiatives.
## Conclusion: Winners Will Be Those Who Most Effectively Use Data and AI
The state of AI in 2024 marks a decisive shift from potential to production reality. Organizations across every industry are deploying artificial intelligence at scale, driving measurable efficiency gains and business value. The data reveals clear winners: companies that invested early in data infrastructure, embraced open source technologies, implemented strong governance, and developed the operational capabilities to deploy AI quickly and safely.
Machine learning adoption continues accelerating, with organizations putting 11x more models into production compared to a year ago while becoming 3x more efficient in their deployment processes. Natural language processing dominates AI applications at 50% of specialized library usage and 75% year-over-year growth. Generative AI has moved beyond hype into practical enterprise applications, with 70% of organizations using vector databases and RAG to customize LLMs with proprietary data.
The preference for open source—with 76% of LLM users choosing open models—reflects enterprise priorities around flexibility, cost control, and avoiding vendor lock-in. Organizations are sophisticated in their model selection, preferring smaller, more efficient models that balance performance with operational realities.
Perhaps most surprisingly, highly regulated industries lead AI adoption. Financial Services and Healthcare & Life Sciences demonstrate that robust governance enables aggressive innovation rather than constraining it. These sectors provide a model for responsible AI scaling that others can follow.
The future belongs to organizations that view AI as a fundamental capability rather than a technology project. Companies that invest in data quality, governance frameworks, and the infrastructure to deploy AI at scale will compound their advantages. Those still experimenting while peers move to production face an increasingly difficult path to catching up.
The winners in every industry will be those who most effectively use data and AI to transform operations, serve customers, and drive innovation. The gap between leaders and laggards is widening. The question isn't whether artificial intelligence will reshape your industry—it's whether your organization will be among those driving that transformation or struggling to respond to it.
## Frequently Asked Questions
### What is the current state of AI?
The current state of AI reflects a decisive shift from experimentation to production deployment. Organizations are putting 11x more AI models into production compared to a year ago, with efficiency gains of 3x in deployment velocity. Generative AI applications are maturing beyond hype, with 70% of companies using vector databases and RAG to customize LLMs. Open source models are preferred by 76% of LLM users, and highly regulated industries like Financial Services and Healthcare lead adoption.
### What stage of AI are we on?
We're transitioning from the early adoption phase to scaled production deployment. While experimentation continues, the ratio of experimental-to-production models has improved from 16:1 to 5:1, indicating organizations have developed the operational capabilities to deploy AI at scale. The focus has shifted from "Can AI work?" to "How do we deploy AI effectively across our organization?" This stage is characterized by infrastructure investment, governance frameworks, and increasingly sophisticated applications.
### Is the AI hype dying down?
No—AI adoption is accelerating, not declining. However, the nature of AI investment is maturing from speculative experimentation to production systems delivering measurable business value. Natural language processing grew 75% year-over-year, vector databases grew 377%, and GPU usage in Financial Services grew 88% in six months. The "hype" is evolving into practical implementation as organizations move beyond pilots to scaled deployments.
### How are most organizations using AI?
Most organizations are using AI for natural language processing applications (50% of specialized Python libraries), including document analysis, customer service chatbots, and content generation. Companies are building RAG applications to customize LLMs with proprietary data rather than relying on off-the-shelf models. Industry-specific applications dominate: fraud detection and market analysis in Financial Services, drug discovery and clinical research in Healthcare, quality control and supply chain optimization in Manufacturing. Real-time AI serving for personalized recommendations and automated decision-making is growing rapidly across all sectors.
Keep up with us
Subscribe
Contents in this story
Recommended for you
Share this post
  * [](https://www.databricks.com/blog/<https:/www.linkedin.com/shareArticle?mini=true&url=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends&summary=&source=>)
  * [](https://www.databricks.com/blog/<https:/twitter.com/intent/tweet?text=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends>)
  * [](https://www.databricks.com/blog/<https:/www.facebook.com/sharer/sharer.php?u=https://www.databricks.com/blog/state-ai-enterprise-adoption-growth-trends>)

## Never miss a Databricks post
Subscribe to our blog and get the latest posts delivered to your inbox
## Sign up
## What's next?
### More from the Authors
