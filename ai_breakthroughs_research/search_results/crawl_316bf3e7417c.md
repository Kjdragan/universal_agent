---
title: "International AI Safety Report"
source: https://internationalaisafetyreport.org
date: unknown
description: ""
word_count: 444
---

 Skip to main content 
!hero banner bg
#  International AI Safety Report 
 Key Updates: Oct and Nov 2025   International AI Safety Report: Jan 2025 
## About the International AI Safety Report
The International AI Safety Report is the world’s first comprehensive review of the latest science on the capabilities and risks of general-purpose AI systems. Written by over 100 independent experts and led by Turing Award winner Yoshua Bengio, it represents the largest international collaboration on AI safety research to date. The Report gives decision-makers a shared global picture of AI's risks and impacts, serving as the authoritative reference for governments and organisations developing AI policies worldwide. It is already shaping debates and informing evidence-based decisions across research and policy communities.
UK AI Security Institute  !AISI logo
 UK AI Security Institute 
Mila - Quebec Artificial Intelligence Institute  !Mila
 Mila - Quebec Artificial Intelligence Institute 
25 November 2025  — Key update 
###   Second Key Update: Technical Safeguards and Risk Management 
This Key Update examines developments in technical approaches to general-purpose AI risk management, from training models to refuse harmful requests to watermarking AI-generated content. Since the publication of the 2025 International AI Safety Report, the number of companies publishing Frontier AI Safety Frameworks has more than doubled, and researchers have refined techniques for training safer models and detecting AI-generated content. However, significant gaps remain: sophisticated attackers can often bypass current defences, and the real-world effectiveness of many safeguards is uncertain. 
!Front cover of report
15 October 2025  — Key update 
###   First Key Update: Capabilities and Risk Implications 
This Key Update covers major breakthroughs in AI capabilities since the publication of the last Report in January 2025 and some implications for major risks. New training techniques that allow AI systems to use more computing power have helped them solve more complex problems, particularly in mathematics, coding, and other scientific disciplines. These capability improvements also have implications for multiple risks, including risks from biological weapons and cyber attacks, and pose new challenges for monitoring and controllability. 
!Front cover of publication, entitled First Key Update
29 January 2025  — Annual Report 
###   International AI Safety Report 2025 
The inaugural International AI Safety Report, published in January 2025, is the first comprehensive review of scientific research on the capabilities and risks of general-purpose AI systems. Led by Turing Award winner Yoshua Bengio and authored by over 100 AI experts. It is backed by 30 countries and international organisations. It represents the largest global collaboration on AI safety to date. 
!Report Front Page
## Use of personal data and cookies
We use cookies and process personal data for the following purposes: **Functional, Embedded external content & Analytics**. 
Customize
DeclineAccept
