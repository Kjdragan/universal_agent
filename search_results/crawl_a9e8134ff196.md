---
title: "unsloth/llama-3-70b-Instruct-bnb-4bit · Hugging Face"
source: https://huggingface.co/unsloth/llama-3-70b-Instruct-bnb-4bit
date: unknown
description: "We’re on a journey to advance and democratize artificial intelligence through open source and open science."
word_count: 288
---

#    Finetune Mistral, Gemma, Llama 2-5x faster with 70% less memory via Unsloth! 
We have a Google Colab Tesla T4 notebook for Llama-3 8b here: <https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing>
  
##    ✨ Finetune for Free 
All notebooks are **beginner friendly**! Add your dataset, click "Run All", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.
Unsloth supports | Free Notebooks | Performance | Memory use  
---|---|---|---  
**Llama-3 8b** | ▶️ Start on Colab | 2.4x faster | 58% less  
**Gemma 7b** | ▶️ Start on Colab | 2.4x faster | 58% less  
**Mistral 7b** | ▶️ Start on Colab | 2.2x faster | 62% less  
**Llama-2 7b** | ▶️ Start on Colab | 2.2x faster | 43% less  
**TinyLlama** | ▶️ Start on Colab | 3.9x faster | 74% less  
**CodeLlama 34b** A100 | ▶️ Start on Colab | 1.9x faster | 27% less  
**Mistral 7b** 1xT4 | ▶️ Start on Kaggle | 5x faster* | 62% less  
**DPO - Zephyr** | ▶️ Start on Colab | 1.9x faster | 19% less  
  * This conversational notebook is useful for ShareGPT ChatML / Vicuna templates.
  * This text completion notebook is for raw text. This DPO notebook replicates Zephyr.
  * * Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.

Downloads last month
    408 
Safetensors[](https://huggingface.co/unsloth/<https:/huggingface.co/docs/safetensors>)
Model size
73B params
Tensor type
F32 
·
BF16 
·
U8 
·
Chat template
Files info
##  Model tree for unsloth/llama-3-70b-Instruct-bnb-4bit [](https://huggingface.co/unsloth/</docs/hub/model-cards#specifying-a-base-model>)
Adapters
8 models
Finetunes
80 models
Quantizations
9 models
##  Space using unsloth/llama-3-70b-Instruct-bnb-4bit 1
##  Collection including unsloth/llama-3-70b-Instruct-bnb-4bit
 18 items •  Updated 25 days ago • 33
Inference providers allow you to run inference using different serverless providers.
