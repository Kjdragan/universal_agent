from mcp.server.fastmcp import FastMCP
from dotenv import load_dotenv
import os
import sys
import json
from datetime import datetime

# Ensure src path for imports
sys.path.append(os.path.abspath("src"))
from tools.workbench_bridge import WorkbenchBridge
from composio import Composio

# Initialize Configuration
load_dotenv()

try:
    mcp = FastMCP("Local Intelligence Toolkit")
except Exception:
    raise


def get_bridge():
    client = Composio(api_key=os.environ.get("COMPOSIO_API_KEY"))
    return WorkbenchBridge(composio_client=client, user_id="user_123")


@mcp.tool()
def workbench_download(
    remote_path: str, local_path: str, session_id: str = None
) -> str:
    """
    Download a file from the Remote Composio Workbench to the Local Workspace.
    """
    bridge = get_bridge()
    result = bridge.download(remote_path, local_path, session_id=session_id)
    if result.get("error"):
        return f"Error: {result['error']}"
    return f"Successfully downloaded {remote_path} to {local_path}. Local path: {result.get('local_path')}"


@mcp.tool()
def workbench_upload(local_path: str, remote_path: str, session_id: str = None) -> str:
    """
    Upload a file from the Local Workspace to the Remote Composio Workbench.
    """
    bridge = get_bridge()
    result = bridge.upload(local_path, remote_path, session_id=session_id)
    if result.get("error"):
        return f"Error: {result['error']}"
    return f"Successfully uploaded {local_path} to {remote_path}."


@mcp.tool()
def write_local_file(path: str, content: str) -> str:
    """
    Write content to a file in the Local Workspace.
    Useful for saving reports, summaries, or code generated by sub-agents.
    """
    try:
        abs_path = os.path.abspath(path)
        os.makedirs(os.path.dirname(abs_path), exist_ok=True)
        with open(abs_path, "w", encoding="utf-8") as f:
            f.write(content)
        return f"Successfully wrote {len(content)} chars to {path}"
    except Exception as e:
        return f"Error writing file: {str(e)}"


@mcp.tool()
def save_corpus(articles: list, workspace_path: str) -> str:
    """
    Save extracted article data to expanded_corpus.json.

    This is a simple file-saving tool. The agent should:
    1. Call webReader for each URL (in parallel batches of 5)
    2. Collect the results into a list of article objects
    3. Call this tool to save the corpus

    Args:
        articles: List of article objects, each with:
            - url: The source URL
            - title: Article title
            - content: FULL markdown content from webReader (NOT summarized)
            - status: "success" or "failed"
        workspace_path: Absolute path to session workspace

    Returns:
        JSON with corpus_path and summary

    Example:
        save_corpus(
            articles=[
                {"url": "https://...", "title": "My Article", "content": "Full markdown...", "status": "success"},
                {"url": "https://...", "title": "", "content": "Error msg", "status": "failed"}
            ],
            workspace_path="/path/to/AGENT_RUN_WORKSPACES/session_xxx"
        )
    """
    try:
        success_count = sum(1 for a in articles if a.get("status") == "success")
        failed_count = len(articles) - success_count

        corpus = {
            "extraction_timestamp": datetime.utcnow().isoformat() + "Z",
            "total_articles": len(articles),
            "successful": success_count,
            "failed": failed_count,
            "articles": articles,
        }

        corpus_path = os.path.join(workspace_path, "expanded_corpus.json")
        os.makedirs(os.path.dirname(corpus_path), exist_ok=True)

        with open(corpus_path, "w", encoding="utf-8") as f:
            json.dump(corpus, f, indent=2, ensure_ascii=False)

        # Calculate total content size
        total_content_size = sum(
            len(a.get("content", "")) for a in articles if a.get("status") == "success"
        )

        return json.dumps(
            {
                "success": True,
                "corpus_path": corpus_path,
                "articles_saved": len(articles),
                "successful": success_count,
                "failed": failed_count,
                "total_content_bytes": total_content_size,
            },
            indent=2,
        )

    except Exception as e:
        return json.dumps({"success": False, "error": str(e)})


if __name__ == "__main__":
    mcp.run()
